{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24786,"status":"ok","timestamp":1666214829813,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"kp4bUGnqpGzs","outputId":"3d7063ae-7496-4e1c-bcd5-c9db32f32ae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"Z8ZkzxmBgGmH"},"source":["# Huggingface install & import\n","https://github.com/huggingface/neuralcoref \n","https://stackoverflow.com/questions/57008612/kernel-died-when-running-neuralcoref "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3828,"status":"ok","timestamp":1665991087045,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"OfI6uJsNjNeC","outputId":"e58b4255-3d30-400c-9b7d-9e46211c13da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy==2.1.0 in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.21.6)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (0.2.4)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (7.0.8)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.23.0)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.0.1)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.0.6)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (0.9.6)\n","Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.6.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (0.10.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.10)\n","Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.64.1)\n"]}],"source":["pip install -U spacy==2.1.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5191,"status":"ok","timestamp":1665991092234,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"le9weguV4cV0","outputId":"c76bd454-4461-4aa6-b392-830ca9f83bf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en_core_web_sm==2.1.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n","\u001b[K     |████████████████████████████████| 11.1 MB 38.3 MB/s \n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"]}],"source":["!python -m spacy download en"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3023,"status":"ok","timestamp":1665991095255,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"s9W7Pog98Qof","outputId":"6a8c49c9-b7f8-4b38-dc0d-990c5199ff14"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:232: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n","  cmdoptions.check_install_build_global(options)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.32)\n"]}],"source":["!pip install Cython --install-option=\"--no-cython-compile\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20381,"status":"ok","timestamp":1665991115627,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"ivZGGB_G5PIj","outputId":"5231b9cd-eca9-47ff-9ddf-67dc96c2a11d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: neuralcoref 4.0\n","Uninstalling neuralcoref-4.0:\n","  Successfully uninstalled neuralcoref-4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting neuralcoref\n","  Using cached neuralcoref-4.0.tar.gz (368 kB)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.21.6)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.24.91)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.23.0)\n","Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2022.9.24)\n","Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.6)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.8)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n","Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.64.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (0.6.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (1.0.1)\n","Requirement already satisfied: botocore<1.28.0,>=1.27.91 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (1.27.91)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.91->boto3->neuralcoref) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.91->boto3->neuralcoref) (1.15.0)\n","Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n","Installing collected packages: neuralcoref\n","    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n","Successfully installed neuralcoref-4.0\n"]}],"source":["!pip uninstall -y neuralcoref \n","\n","!pip install neuralcoref --no-binary neuralcoref"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0xVSOk6BfAk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8829,"status":"ok","timestamp":1665991124453,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"Ptn0v3aUhXMR","outputId":"4dd2c45e-471c-4907-96b0-7e8e67ab3c0c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 40155833/40155833 [00:04<00:00, 8219330.56B/s] \n"]},{"output_type":"execute_result","data":{"text/plain":["<spacy.lang.en.English at 0x7f533d3e7910>"]},"metadata":{},"execution_count":6}],"source":["import neuralcoref\n","import spacy\n","nlp = spacy.load('en')\n","neuralcoref.add_to_pipe(nlp)"]},{"cell_type":"markdown","metadata":{"id":"ivsLas4UKIb_"},"source":["# Setup"]},{"cell_type":"code","source":["data_path = \"/content/drive/My Drive/AmbiCoref/data_ealc/\""],"metadata":{"id":"hryjT97axLy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOWvAEVoKKfp"},"outputs":[],"source":["import pandas as pd\n","col_names = ['Category','%Name1','%Name2','%Missing','%Both','%Other','Model']\n","df_all = pd.DataFrame(columns = col_names)"]},{"cell_type":"markdown","metadata":{"id":"vPKmzJepUvNO"},"source":["# Type ECO"]},{"cell_type":"markdown","metadata":{"id":"8WE3s78LimTw"},"source":["## unambiguous ECO-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcvi_nccS92K"},"outputs":[],"source":["file = open(data_path+\"sentences/ECO-1_unambiguous.txt\", \"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJp1wu8d0vYA","executionInfo":{"status":"ok","timestamp":1665973605975,"user_tz":240,"elapsed":6,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"42efbab4-df84-42d5-8512-ed6d5b05b267"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11336"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32YSmz0nS92L"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[span_index_that+1:span_index_that+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"VzsR1EaTdbqT"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZto6yKxdbqU"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Idv1I6C6dbqU"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-1_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"xpZiwDRTiu4B"},"source":["## ambiguous ECO-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyMGZmyHiu4B"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECO-1_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJKrx0Q30-cb","executionInfo":{"status":"ok","timestamp":1666215836598,"user_tz":240,"elapsed":3,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"73aa4972-7be6-4e18-9227-1848e590c4b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11336"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYAlKesaiu4B"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[span_index_that+1:span_index_that+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"OIkK6iRFiu4C"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZI1bZxLiu4C"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3ulTCLRiu4C"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-1_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"Yei-Q9Pwi-fI"},"source":["## unambiguous ECO-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDBojtQii-fJ"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECO-2_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CLaF5wJrpwD","executionInfo":{"status":"ok","timestamp":1666215854802,"user_tz":240,"elapsed":330,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"f5e51eed-3053-4750-a8e7-9b287248c958"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11336"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wMz3hMri-fJ"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[span_index_that+1:span_index_that+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"q0dzYzE0i-fJ"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APVkEouZi-fJ"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEzSbzfXi-fK"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-2_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"gCXcmEiEjg3K"},"source":["## ambiguous ECO-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uawbeGsOjg3L"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECO-2_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5ov3geD3O2K","executionInfo":{"status":"ok","timestamp":1665975079608,"user_tz":240,"elapsed":3,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"7467345a-4ff3-4fb6-b37c-2a8dde9ab85c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11336"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-VlvAjRjg3L"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[span_index_that+1:span_index_that+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"WupO9b_sjg3L"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3xapF0Ljg3L"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOdwLnSVjg3M"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-2_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"deavivptPpHA"},"source":["# Type ECS"]},{"cell_type":"markdown","metadata":{"id":"yqcrHEXtmnc6"},"source":["## unambiguous ECS-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbUJlNH2dMCF"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECS-1_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjCDZplG3TBO","executionInfo":{"status":"ok","timestamp":1665976101769,"user_tz":240,"elapsed":2,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"5ccccd17-99c0-4977-d990-a02b2f3f6abb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4472"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYD9MDx4qaVz"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[-3:-2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"MyXsZM1-nDb0"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHbXB7fUnDb0"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGe4NafDnDb1"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-1_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"tkhpf68VoXuX"},"source":["## ambiguous ECS-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_KNfrO6oXuX"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECS-1_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zw4wcGtP31Fy","executionInfo":{"status":"ok","timestamp":1665976253733,"user_tz":240,"elapsed":5,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"e84f454a-3f66-46b7-9fc6-49ca92735689"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4472"]},"metadata":{},"execution_count":138}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4e5eBspoXuY"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[-3:-2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"PI4QwNshoXuY"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-f_EVdToXuY"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iyhc4H3oXuY"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-1_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"bjyki3x-osCd"},"source":["## unambiguous ECS-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xsmf8DO6osCo"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECS-2_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHQPB0zS4DWj","executionInfo":{"status":"ok","timestamp":1665976372157,"user_tz":240,"elapsed":6,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"d9e28018-e163-41d4-abd3-4ace6079b931"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4472"]},"metadata":{},"execution_count":154}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhrvNXn1osCo"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[-3:-2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"z21jsce3osCo"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ5Pc3Z1osCo"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I3IHZEAosCo"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-2_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"jOCq2T4goy5a"},"source":["## ambiguous ECS-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74LcjhpYoy5a"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/ECS-2_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQ6lg9Y04GuU","executionInfo":{"status":"ok","timestamp":1665976497167,"user_tz":240,"elapsed":3,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"29a0a9ac-df1c-442c-8005-5b66fcbba14e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4472"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4uNeCRooy5b"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_that = s.index('that')\n","  word_index_that = words.index(\"that\")\n","  span_index_that = spans.index(\"that\")\n","  subString_before_that = s[:ch_index_that]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_that:\n","    name2 = doc[span_index_that-1:span_index_that]\n","    num_span_name2 = 2 + words[word_index_that-1].count(\"-\")*2\n","    name2 = doc[span_index_that-num_span_name2:span_index_that]\n","  else:\n","    name2 = doc[span_index_that-1:span_index_that]\n","\n","  pronoun = doc[-3:-2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"6gIfvKHXoy5b"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I18EIMrkoy5b"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-36Xv2ooy5b"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-2_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"Ojzzco9WjxUm"},"source":["# Type IC"]},{"cell_type":"markdown","metadata":{"id":"OKceKsMXrY0K"},"source":["## unambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ToDMwlcrY0K"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/IC_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hd-E_JU24Qu6","executionInfo":{"status":"ok","timestamp":1665977032661,"user_tz":240,"elapsed":4,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"262a38d5-b67e-4a0a-ebd3-33e2958da817"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8424"]},"metadata":{},"execution_count":186}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NQUe9xmrY0L"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_bc = s.index('because')\n","  word_index_bc = words.index(\"because\")\n","  span_index_bc = spans.index(\"because\")\n","  subString_before_bc = s[:ch_index_bc]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_bc:\n","    name2 = doc[span_index_bc-1:span_index_bc]\n","    num_span_name2 = 2 + words[word_index_bc-1].count(\"-\")*2\n","    name2 = doc[span_index_bc-num_span_name2:span_index_bc]\n","  else:\n","    name2 = doc[span_index_bc-1:span_index_bc]\n","\n","  pronoun = doc[span_index_bc+1:span_index_bc+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"Asg9e7qKrY0L"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"203BGv-6rY0L"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdqcIUj1rY0L"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"IC_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"a0Abn-GLq_vj"},"source":["## ambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bt6RBPMOjxUn"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/IC_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qji3Cany4lgY","executionInfo":{"status":"ok","timestamp":1665977273200,"user_tz":240,"elapsed":3,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"f6ecb476-4390-4993-ec52-f9514813a477"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8424"]},"metadata":{},"execution_count":202}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYfgLbfBqoDY"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","\n","\n","  ch_index_bc = s.index('because')\n","  word_index_bc = words.index(\"because\")\n","  span_index_bc = spans.index(\"because\")\n","  subString_before_bc = s[:ch_index_bc]\n","\n","  name1 = doc[0:1]\n","  name2 = None\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","\n","  if \" the \" in subString_before_bc:\n","    name2 = doc[span_index_bc-1:span_index_bc]\n","    num_span_name2 = 2 + words[word_index_bc-1].count(\"-\")*2\n","    name2 = doc[span_index_bc-num_span_name2:span_index_bc]\n","  else:\n","    name2 = doc[span_index_bc-1:span_index_bc]\n","\n","  pronoun = doc[span_index_bc+1:span_index_bc+2]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1"]},{"cell_type":"markdown","metadata":{"id":"n8TX_AYPYUHV"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hx-XKW5WYUHV"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwpwi_vpYUHV"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"IC_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"Qk-rfskLXU5B"},"source":["# Type TOP"]},{"cell_type":"markdown","metadata":{"id":"SF1Lym_tsiMO"},"source":["## unambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-p3xGfwsiMP"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/TOP_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5h8tOktM4odi","executionInfo":{"status":"ok","timestamp":1666215902198,"user_tz":240,"elapsed":346,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"3f1a80a4-ca78-4ef6-a8ed-fa9ac2079303"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8424"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_f8aJLZusiMQ"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","  name1 = doc[0:1]\n","  name2_index_start = 0\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","    name2_index_start = num_span_name1 + 1\n","  \n","  if \"by\" in words:\n","    span_index_by = spans.index(\"by\")\n","    name2_index_start = span_index_by + 1\n","\n","  if spans[name2_index_start] == 'the':\n","    name2 = doc[name2_index_start:name2_index_start+2]\n","  else:\n","    name2 = doc[name2_index_start:name2_index_start+1]\n","\n","  span_index_pronoun = -1\n","  if \"she\" in words:\n","    span_index_pronoun = spans.index(\"she\")\n","  else:\n","    span_index_pronoun = spans.index(\"he\")\n","  pronoun = doc[span_index_pronoun:span_index_pronoun+1]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1\n","  \n","  "]},{"cell_type":"markdown","metadata":{"id":"7vZQ6UbfsiMQ"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97IUF1cQsiMQ"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d49G4VGSsiMQ"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"TOP_unambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"ndJw-TGgsTww"},"source":["## ambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiggVOSlXU5C"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/data_ealc/sentences/TOP_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","source":["len(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-QlenHW4tWC","executionInfo":{"status":"ok","timestamp":1666012599473,"user_tz":240,"elapsed":13,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}},"outputId":"fa21a35e-e7cc-456e-a63c-eb273713f6af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8424"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nQ65EsHvMpB"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0\n","\n","\n","for s in sentences:\n","  count_total += 1\n","\n","\n","  doc = nlp(s)\n","  words = s.split(\" \")\n","  spans = s.replace('-', ' - ').split(' ')\n","\n","  name1 = doc[0:1]\n","  name2_index_start = 0\n","  if words[0] == 'The': \n","    num_span_name1 = 2 + words[1].count(\"-\")*2\n","    name1 = doc[:num_span_name1] \n","    name2_index_start = num_span_name1 + 1\n","  \n","  if \"by\" in words:\n","    span_index_by = spans.index(\"by\")\n","    name2_index_start = span_index_by + 1\n","\n","  if spans[name2_index_start] == 'the':\n","    name2 = doc[name2_index_start:name2_index_start+2]\n","  else:\n","    name2 = doc[name2_index_start:name2_index_start+1]\n","\n","  span_index_pronoun = -1\n","  if \"she\" in words:\n","    span_index_pronoun = spans.index(\"she\")\n","  else:\n","    span_index_pronoun = spans.index(\"he\")\n","  pronoun = doc[span_index_pronoun:span_index_pronoun+1]\n","\n","  if not pronoun._.is_coref:\n","    continue\n","  cluster = pronoun._.coref_cluster\n","\n","  if cluster is None:\n","    continue\n","\n","  if name1 in cluster:\n","    if name2 not in cluster:\n","      count_pos1 += 1\n","    else:\n","      count_both += 1\n","  elif name2 in cluster:\n","    count_pos2 += 1\n","  elif len(cluster) > 1 :\n","    count_other += 1\n","  \n","  "]},{"cell_type":"markdown","metadata":{"id":"lAiYst0YsKBU"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wUfaR50sKBV"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3uVzaO7sKBW"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"TOP_ambiguous_active\" \n","df_temp['Model'] = \"Hugging_face\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","source":["# Final output"],"metadata":{"id":"tvCzGHVu-mSG"}},{"cell_type":"code","source":["df_all.to_csv(data_path+\"results_Hugging_face.csv\")"],"metadata":{"id":"KAetmj7OYeA5"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["Z8ZkzxmBgGmH"],"machine_shape":"hm","provenance":[{"file_id":"1c2tK-_d41vZ8pf6cxfAMderzGLJ6BFst","timestamp":1644887814780}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15934,"status":"ok","timestamp":1665988525457,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"4G-silzAW-Mj","outputId":"d6cd0ba6-684c-4b4b-e8d2-866f814ed85e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"yB3M9o1B0hYn"},"source":["# Allen NLP install & import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3639,"status":"ok","timestamp":1666065356078,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"0tbNay-I0dWc","outputId":"9ede2252-c962-40af-d874-d18d7fd5a7c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: allennlp==2.1.0 in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: allennlp-models==2.1.0 in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.7)\n","Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.7.3)\n","Requirement already satisfied: transformers<4.4,>=4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (4.3.3)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (8.14.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.99)\n","Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.1.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.0.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.1.0)\n","Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.24.92)\n","Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.5.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.6.4)\n","Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.18.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.1.97)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (4.64.1)\n","Requirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.7.1)\n","Requirement already satisfied: torchvision<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.8.2)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.23.0)\n","Requirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.21.6)\n","Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.0.12)\n","Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp-models==2.1.0) (1.1)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from allennlp-models==2.1.0) (6.1.1)\n","Requirement already satisfied: conllu==4.4 in /usr/local/lib/python3.7/dist-packages (from allennlp-models==2.1.0) (4.4)\n","Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp-models==2.1.0) (1.1)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp==2.1.0) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp==2.1.0) (0.6.0)\n","Requirement already satisfied: botocore<1.28.0,>=1.27.92 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp==2.1.0) (1.27.92)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.92->boto3<2.0,>=1.14->allennlp==2.1.0) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.92->boto3<2.0,>=1.14->allennlp==2.1.0) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.92->boto3<2.0,>=1.14->allennlp==2.1.0) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2.10)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.6.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.11.3)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.3.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (8.0.17)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.10.0.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.10)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.4.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.10.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.7.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (57.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1,>=2.1.0->allennlp==2.1.0) (5.2.1)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==2.1.0) (3.17.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.9.0,>=0.8.1->allennlp==2.1.0) (7.1.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (5.0.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (0.0.53)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1,>=2.1.0->allennlp==2.1.0) (7.1.2)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==2.1.0) (0.2.5)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==2.1.0) (1.5.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->allennlp==2.1.0) (1.2.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.11.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (0.7.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (22.1.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==2.1.0) (3.1.0)\n"]}],"source":["pip install allennlp==2.1.0 allennlp-models==2.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVH7w8DGiN1J"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_6eQUL_02Q8"},"outputs":[],"source":["from allennlp.predictors.predictor import Predictor\n","import allennlp_models.tagging"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666319241357,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"PLOc_NIIAOJZ"},"outputs":[],"source":["predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz\")"]},{"cell_type":"markdown","metadata":{"id":"ivsLas4UKIb_"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOWvAEVoKKfp"},"outputs":[],"source":["import pandas as pd\n","col_names = ['Category','%Name1','%Name2','%Missing','%Both','%Other','Model']\n","df_all = pd.DataFrame(columns = col_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAikcurwqovE"},"outputs":[],"source":["data_path = \"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data\""]},{"cell_type":"markdown","metadata":{"id":"BjgOqqDxCLi9"},"source":["# Run Model\n","\n","https://github.com/allenai/allennlp-models/blob/main/allennlp_models/coref/models/coref.py"]},{"cell_type":"markdown","metadata":{"id":"T0yzfrGuOYCN"},"source":["## Type ECO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5g3dx5JOan1"},"outputs":[],"source":["# return values:\n","# 1: pos1\n","# 2: pos2\n","# -1: missing\n","# 3: both\n","# 4: other\n","\n","def run_coref(s):\n","  output = predictor.predict(document=s[:-1])\n","  words = s.split()\n","  word_index_that = words.index(\"that\")\n","\n","  name1 = (0,0)\n","  if words[0] == 'The':\n","    name1 = (0,1)\n","\n","  name2 = (word_index_that-1, word_index_that-1)\n","  if words[word_index_that-2]=='the':\n","    name2 = (word_index_that-2, word_index_that-1)\n","\n","  pronoun = (word_index_that+1, word_index_that+1)\n","\n","\n","  for c in output['clusters']:\n","    ref = set()\n","    target = False\n","    \n","    for span in c:\n","      if tuple(span) == pronoun:\n","        target = True\n","      else:\n","        ref.add(tuple(span))\n","\n","    if not target:\n","      continue\n","\n","    if name1 in ref and name2 not in ref:\n","      return 1\n","    elif name2 in ref and name1 not in ref:\n","      return 2\n","    elif name1 in ref and name2 in ref:\n","      return 3\n","    else:\n","      if len(ref) > 1:\n","        return 4\n","  \n","  return -1"]},{"cell_type":"markdown","metadata":{"id":"TJVlA3pDOptf"},"source":["### unambiguous ECO-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xbsz3ESIOwiU"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECO-1_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWIf7OpcU8Od"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1kSRhttXfsv"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"uXY3vWubP631"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1665990434641,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"UJ0MleMkmw6b","outputId":"949b9cf1-442f-4c89-e06c-84cac01bfe03"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------\n","%Name1 = 0.575423429781228\n","%Name2 = 0.12041284403669725\n","%Missing = 0.2837861679604799\n","%Both =  0.02037755822159492\n","%Other = 0.0\n"]}],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2LEjbyurp-G"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-1_unambiguous\" \n","df_temp['Model'] = \"Allen_NLP\"\n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"c2CdK6crXutC"},"source":["### ambiguous ECO-1 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSslMXSTXutC"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECO-1_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hg787mqfXutD"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kjc6wDkvXutD"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"BhZd11mdXutE"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1tGVo9fGXutE","outputId":"d1bb1c82-f307-4cc9-b0f1-9e359a38b8e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------\n","%Name1 = 0.5665137614678899\n","%Name2 = 0.18216302046577276\n","%Missing = 0.21912491178546226\n","%Both =  0.03219830628087509\n","%Other = 0.0\n"]}],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IpryxeeDXutE"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-1_ambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"AeEPF9_TYFpR"},"source":["### unambiguous ECO-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qfnngFsYFpS"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECO-2_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imWHAwtyYFpS"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grcG3HVuYFpT"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"F7gWoNdYYFpT"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGslyKpBYFpT"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzhZ6tFFYFpT"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-2_unambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"RnIevrjnYUHT"},"source":["### ambiguous ECO-2 active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSf5DprPYbnJ"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECO-2_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOppww4EYUHU"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKmZAoo5YUHU"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"n8TX_AYPYUHV"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hx-XKW5WYUHV"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwpwi_vpYUHV"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECO-2_ambiguous\"\n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"dtfOjR89P9aw"},"source":["## Type ECS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2shvLwrt5qm"},"outputs":[],"source":["def run_coref(s):\n","  output = predictor.predict(document=s[:-1])\n","  words = s.split()\n","  word_index_that = words.index(\"that\")\n","\n","  name1 = (0,0)\n","  if words[0] == 'The':\n","    name1 = (0,1)\n","\n","  name2 = (word_index_that-1, word_index_that-1)\n","  if words[word_index_that-2]=='the':\n","    name2 = (word_index_that-2, word_index_that-1)\n","\n","  len_sentence = len(words)\n","  pronoun = (len_sentence-1, len_sentence-1)\n","\n","\n","  for c in output['clusters']:\n","    ref = set()\n","    target = False\n","    \n","    for span in c:\n","      if tuple(span) == pronoun:\n","        target = True\n","      else:\n","        ref.add(tuple(span))\n","\n","    if not target:\n","      continue\n","\n","    if name1 in ref and name2 not in ref:\n","      return 1\n","    elif name2 in ref and name1 not in ref:\n","      return 2\n","    elif name1 in ref and name2 in ref:\n","      return 3\n","    else:\n","      if len(ref) > 1:\n","        print(ref)\n","        return 4\n","  \n","  return -1"]},{"cell_type":"markdown","metadata":{"id":"cWdC7DgP6C2L"},"source":["### unambiguous ECS-1 active\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyhWkKf-6L0j"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECS-1_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qxhD7DMQhWK"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CJ75jiSQZhz"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"Vq04ZLs0ZqOA"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666035931754,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"FH2xb4wGZudI","outputId":"dc12fb83-d22e-434c-ea7a-7d18e4334a0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","%Name1 = 0.2737030411449016\n","%Name2 = 0.28600178890876565\n","%Missing = 0.43067978533094814\n","%Both =  0.009615384615384616\n","%Other = 0.0\n"]}],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmEqjLmGZqOB"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-1_unambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])\n"]},{"cell_type":"markdown","metadata":{"id":"fb9U7M3j6ZRo"},"source":["### ambiguous ECS-1 active\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11kgxYdW6ZRo"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECS-1_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1MWlzu06ZRo"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3NEksMd6ZRo"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"qXfLWX1iaf69"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXrvXx6Maf6-"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UQJueIvaf6-"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-1_ambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"uJnvNZLO6ZkS"},"source":["### unambiguous ECS-2 active\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DSxcV626ZkT"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECS-2_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnHr1Iqn6ZkT"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR1rX9m_6ZkT"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"DnA7vWtYa_Fd"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_sY6fSaa_Fd"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fx2SLk6Sa_Fe"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-2_unambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"p8XU-0_l6Z0W"},"source":["### ambiguous ECS-2 active\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyraBbTy6Z0W"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/ECS-2_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3BW51096Z0X"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nC2WJFCB6Z0X"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"PTMJXOZMbrN2"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HirgCKxbrN2"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlOu7CXPbrN3"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"ECS-2_ambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"6wKCHhgc1jrS"},"source":["## Type IC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwyNeF8Xu9rc"},"outputs":[],"source":["# return values:\n","# 1: pos1\n","# 2: pos2\n","# -1: missing\n","# 3: both\n","# 4: other\n","\n","def run_coref(s):\n","  output = predictor.predict(document=s[:-1])\n","  words = s.split()\n","  word_index_that = words.index(\"because\")\n","\n","  name1 = (0,0)\n","  if words[0] == 'The':\n","    name1 = (0,1)\n","\n","  name2 = (word_index_that-1, word_index_that-1)\n","  if words[word_index_that-2]=='the':\n","    name2 = (word_index_that-2, word_index_that-1)\n","\n","  pronoun = (word_index_that+1, word_index_that+1)\n","\n","\n","  for c in output['clusters']:\n","    ref = set()\n","    target = False\n","    \n","    for span in c:\n","      if tuple(span) == pronoun:\n","        target = True\n","      else:\n","        ref.add(tuple(span))\n","\n","    if not target:\n","      continue\n","\n","    if name1 in ref and name2 not in ref:\n","      return 1\n","    elif name2 in ref and name1 not in ref:\n","      return 2\n","    elif name1 in ref and name2 in ref:\n","      return 3\n","    else:\n","      if len(ref) > 1:\n","        print(ref)\n","        return 4\n","  \n","  return -1"]},{"cell_type":"markdown","metadata":{"id":"U0PQwBur6-ph"},"source":["### unambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZ2UHFbj6-pi"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/IC_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NE4bfBx6-pi"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVP6L0px6-pi"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"jXgekt9JcxE-"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmRzy0hWcxE_"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WaKHGx8cxE_"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"IC_unambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp]) "]},{"cell_type":"markdown","metadata":{"id":"Ezy0vfoD6yNI"},"source":["### ambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVq59qEV6xlE"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/IC_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ms41wZHH2Csp"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3YIxTWt2BQ2"},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"thIiyvw6cZBT"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJNLQrl1cZBT"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tc48__XwcZBU"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"IC_ambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"Onyb4eHwkJt2"},"source":["## Type TOP"]},{"cell_type":"code","source":["# return values:\n","# 1: pos1\n","# 2: pos2\n","# -1: missing\n","# 3: both\n","# 4: other\n","\n","def run_coref(s):\n","  output = predictor.predict(document=s[:-1])\n","  words = s.split()\n","  pronoun_index = -1\n","  if \"she\" in words:\n","    pronoun_index = words.index(\"she\")\n","  else:\n","    pronoun_index = words.index(\"he\")\n","  pronoun = (pronoun_index, pronoun_index)\n","  \n","\n","  output = predictor.predict(document=s[:-1])\n","  words = s.split()\n","  pronoun_index = -1\n","  if \"she\" in words:\n","    pronoun_index = words.index(\"she\")\n","  else:\n","    pronoun_index = words.index(\"he\")\n","  pronoun = (pronoun_index, pronoun_index)\n","\n","\n","  name1 = (0,0)\n","  name2_index_start = 2 \n","  if words[0] == 'The':\n","    name1 = (0,1)\n","    name2_index_start = 3\n","\n","  if \"by\" in words:\n","    name2_index_start = words.index(\"by\") + 1\n","\n","  if words[name2_index_start]=='the':\n","    name2 = (name2_index_start, name2_index_start+1)\n","  else:\n","    name2 = (name2_index_start, name2_index_start)\n","\n","  for c in output['clusters']:\n","    ref = set()\n","    target = False\n","    \n","    for span in c:\n","      if tuple(span) == pronoun:\n","        target = True\n","      else:\n","        ref.add(tuple(span))\n","\n","    if not target:\n","      continue\n","\n","    if name1 in ref and name2 not in ref:\n","      return 1\n","    elif name2 in ref and name1 not in ref:\n","      return 2\n","    elif name1 in ref and name2 in ref:\n","      return 3\n","    else:\n","      if len(ref) > 1:\n","        print(ref)\n","        return 4\n","  \n","  return -1"],"metadata":{"id":"P_2eTjM3IHdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5LLHNpGIMrOg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lT5cGC067Enp"},"source":["###unambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJqp2PKZ7NDl"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/TOP_unambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQdeFhKUk_5s"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lU2_wcQkPXZ","executionInfo":{"status":"ok","timestamp":1666319581585,"user_tz":240,"elapsed":93,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}}},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"XtnT-tiBdWhr"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666054783930,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"},"user_tz":240},"id":"96qckGI1dWhr","outputId":"36effd18-9065-4cc8-ae86-ee3b5ebad07b"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","%Name1 = 0.20845204178537513\n","%Name2 = 0.636633428300095\n","%Missing = 0.13437796771130103\n","%Both =  0.018399810066476733\n","%Other = 0.002136752136752137\n"]}],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNJnhv-odWhs"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"TOP_unambiguous\"\n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","metadata":{"id":"glJJty267VJq"},"source":["###ambiguous active"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rs4pWvmA7VJq"},"outputs":[],"source":["file = open(r\"/content/drive/My Drive/AmbiCoref/AmbiCoref/Data/sentences/TOP_ambiguous.txt\",\"r\")\n","sentences = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gba_rPtR7VJq"},"outputs":[],"source":["count_pos1 = 0\n","count_pos2 = 0\n","count_total = 0\n","count_other = 0\n","count_both = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7XTSBiR7VJq","executionInfo":{"status":"ok","timestamp":1666319613598,"user_tz":240,"elapsed":85,"user":{"displayName":"Yuewei Yuan","userId":"03266189347381662209"}}},"outputs":[],"source":["for i, s in enumerate(sentences):\n","  \n","  count_total = count_total + 1\n","  result = run_coref(s)\n","  if result == 1:\n","    count_pos1 = count_pos1 + 1\n","  elif result == 2:\n","    count_pos2 = count_pos2 + 1\n","  elif result == 3:\n","    count_both = count_both + 1\n","  elif result == 4:\n","    count_other = count_other + 1\n"]},{"cell_type":"markdown","metadata":{"id":"VzsR1EaTdbqT"},"source":["#### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZto6yKxdbqU"},"outputs":[],"source":["name1_perc = count_pos1 / count_total\n","name2_perc = count_pos2 / count_total\n","missing_perc = (count_total -count_pos1 - count_pos2 - count_other - count_both) / count_total\n","both_perc = count_both / count_total\n","other_perc = count_other / count_total\n","\n","print(\"-------------\")\n","print(\"%Name1 = \" + str(name1_perc))\n","print(\"%Name2 = \" + str(name2_perc))\n","print(\"%Missing = \" + str(missing_perc))\n","print(\"%Both =  \" + str(both_perc))\n","print(\"%Other = \" + str(other_perc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Idv1I6C6dbqU"},"outputs":[],"source":["result_temp = [(name1_perc, name2_perc, missing_perc, both_perc, other_perc)]\n","df_temp = pd.DataFrame(result_temp, columns=['%Name1','%Name2','%Missing','%Both','%Other'] )\n","df_temp['Category'] = \"TOP_ambiguous\" \n","df_temp['Model'] = \"Allen_NLP\" \n","df_all = pd.concat([df_all, df_temp])"]},{"cell_type":"markdown","source":["# Final output"],"metadata":{"id":"Tafp3bgaKbSO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ITaUHeKKWHP"},"outputs":[],"source":["df_all.to_csv(data_path+\"Results/results_Allen_NLP.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","toc_visible":true,"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}